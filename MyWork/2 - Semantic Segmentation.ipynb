{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMchVnigcUgKye671GTIus7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"NQaPKLidH45a"}},{"cell_type":"markdown","source":["In this notebook, we will train a deeplabv3 semantic segmentation model based on the resnet50 network structure, using the previous dataset and labeling results for training."],"metadata":{"id":"yByfDG8cjF5-"}},{"cell_type":"markdown","source":["#1 Load Library and data preprocessing"],"metadata":{"id":"QXxki7W_LR-A"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9OjeKDzADKo","executionInfo":{"status":"ok","timestamp":1691140539804,"user_tz":-60,"elapsed":17874,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}},"outputId":"366f7270-f2ea-48f8-d258-f036e81a48e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","repo = \"/content/drive/MyDrive/Dissertation/MyWork/Dataset/\" #will be useful to loop over the files later on."]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","import cv2\n","import torchvision.models.segmentation\n","import torch\n","import torchvision.transforms as tf\n","from torchvision import transforms, datasets, models\n","from PIL import Image\n","import os\n","import shutil\n"],"metadata":{"id":"n7o5bQTqjFR3","executionInfo":{"status":"ok","timestamp":1691140547048,"user_tz":-60,"elapsed":5252,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Image preprocessing and training/testing dataset division"],"metadata":{"id":"H4dqw3ttby4X"}},{"cell_type":"code","source":["# # define file path\n","# input_folder = repo + 'GT1024'\n","# output_folder = repo + 'GT'\n","\n","# for filename in os.listdir(input_folder):\n","#     if filename.endswith('.png'):\n","#         input_path = os.path.join(input_folder, filename)\n","#         output_path = os.path.join(output_folder, filename)\n","\n","#         # resize to 64x64\n","#         img = Image.open(input_path)\n","#         img = img.resize((64, 64), Image.ANTIALIAS)\n","\n","#         # save the image\n","#         img.save(output_path)\n","#         print( filename + 'done。')\n","# print('all image is done。')\n"],"metadata":{"id":"sFzmGhDhb1nW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # check the number of image file\n","# lll = \"/content/drive/MyDrive/Dissertation/MyWork/Dataset/GT\"\n","# file_count = len(os.listdir(lll))\n","\n","# print(f'file number is: {file_count} ')\n"],"metadata":{"id":"qOgIgDqVpTgz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Split 1000 pictures as a test set"],"metadata":{"id":"swfd3YSub2bR"}},{"cell_type":"code","source":["# for i in range(9001, 10001):\n","#     name1 = output_folder + \"/Sample_\" + str(i) + \"_gt.png\"\n","#     name2 = repo + \"Blood_Cancer/Sample_\" + str(i) + \".tiff\"\n","#     path1 = repo + \"TestGT/Sample_\" + str(i) + \"_gt.png\"\n","#     path2 = repo + \"TestBC/Sample_\" + str(i) + \".tiff\"\n","\n","#     shutil.move(name1, path1)\n","#     shutil.move(name2, path2)\n","#     print(str(i) + ' done。')\n","\n","# print('data set split is done')"],"metadata":{"id":"0iUfDefPmwrf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2 Train the model"],"metadata":{"id":"AEa1rD0yFHXL"}},{"cell_type":"markdown","source":["Define basic parameters"],"metadata":{"id":"vZxR_bJhFHRO"}},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(\"using {} device.\".format(device))"],"metadata":{"id":"9VrV2t5RDnaC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691140577217,"user_tz":-60,"elapsed":422,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}},"outputId":"347e3b82-d27a-4889-a62d-e568310005c4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["using cuda device.\n"]}]},{"cell_type":"code","source":["Learning_Rate=1e-5\n","width=height=800 # image width and height\n","batchSize=3"],"metadata":{"id":"LhyZGGeRLK6s","executionInfo":{"status":"ok","timestamp":1691140580351,"user_tz":-60,"elapsed":436,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_folder= repo + \"Blood_Cancer\"\n","gt_folder = repo + \"GT\"\n","list_img = os.listdir(train_folder)\n","list_gt = os.listdir(gt_folder)"],"metadata":{"id":"mmrDXN4TLNUO","executionInfo":{"status":"ok","timestamp":1691140684507,"user_tz":-60,"elapsed":101926,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["transformImg = tf.Compose([tf.ToPILImage(),tf.Resize((height,width)), tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n","transformAnn = tf.Compose([tf.ToPILImage(),tf.Resize((height,width)), tf.ToTensor()])"],"metadata":{"id":"A-ZD7U84LPRv","executionInfo":{"status":"ok","timestamp":1691158649974,"user_tz":-60,"elapsed":402,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["Define some functions to assist training\n","\n","1, ReadRandomImage and LoadBatch: Randomly select a few pictures to load the pre-trained model, and save the model locally after a few simple training steps\n","\n","2, ReadNextImage and LoadBatchAll: Load all data set for fully train the model"],"metadata":{"id":"2GL3DXMHOuev"}},{"cell_type":"code","source":["def ReadRandomImage():\n","    idx = np.random.randint(0,len(list_img)) # Pick random image\n","    img = cv2.imread(os.path.join(train_folder,list_img[idx]))\n","    img_GT = cv2.imread(os.path.join(gt_folder,list_img[idx].replace(\".tiff\",\"_gt.png\")),0)\n","\n","    ann_map = np.zeros(img_GT.shape[0:2],np.float32) # Segmentation map\n","    ann_map[ img_GT == 255 ] = 1\n","\n","    img=transformImg(img)\n","    ann_map=transformAnn(ann_map)\n","\n","    return img, ann_map"],"metadata":{"id":"12CczCEuLTcR","executionInfo":{"status":"ok","timestamp":1691140684508,"user_tz":-60,"elapsed":3,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def ReadNextImage(idx):\n","    img = cv2.imread(os.path.join(train_folder,list_img[idx]))\n","    img_GT = cv2.imread(os.path.join(gt_folder,list_img[idx].replace(\".tiff\",\"_gt.png\")),0)\n","\n","    ann_map = np.zeros(img_GT.shape[0:2],np.float32) # Segmentation map\n","    ann_map[ img_GT == 255 ] = 1\n","\n","    img=transformImg(img)\n","    ann_map=transformAnn(ann_map)\n","\n","    return img, ann_map"],"metadata":{"id":"-16RpghvLXBe","executionInfo":{"status":"ok","timestamp":1691140684508,"user_tz":-60,"elapsed":3,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def LoadBatch(): # Load batch of images\n","    images = torch.zeros([batchSize,3,height,width])\n","    ann = torch.zeros([batchSize, height, width])\n","\n","    for i in range(batchSize):\n","        images[i],ann[i]=ReadRandomImage()\n","\n","    return images, ann"],"metadata":{"id":"_WPRbECfLVpP","executionInfo":{"status":"ok","timestamp":1691140685826,"user_tz":-60,"elapsed":2,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def LoadBatchAll(idx): # Load batch of images\n","    images = torch.zeros([batchSize,3,height,width])\n","    ann = torch.zeros([batchSize, height, width])\n","\n","    for i in range(batchSize):\n","        images[i],ann[i]=ReadNextImage(idx)\n","        idx = idx + 1\n","\n","    return images, ann"],"metadata":{"id":"1PjGa45SiCJH","executionInfo":{"status":"ok","timestamp":1691140687684,"user_tz":-60,"elapsed":3,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Randomly train, read the pre-trained weights"],"metadata":{"id":"VUmXFHgl4Iu9"}},{"cell_type":"code","source":["Net = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n","\n","Net.classifier[4] = torch.nn.Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1)) # Change final layer to 3 classes\n","Net=Net.to(device)\n","optimizer=torch.optim.Adam(params=Net.parameters(),\n","                           lr=Learning_Rate)\n","                          #  ,weight_decay=Weight_Decay) # Create adam optimizer\n","criterion = torch.nn.CrossEntropyLoss() # Set loss function"],"metadata":{"id":"n-u1caoz4Idv","executionInfo":{"status":"ok","timestamp":1691158643787,"user_tz":-60,"elapsed":892,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["Best_loss = 1\n","Best_loss = [Best_loss]\n","model_path = repo + \"weight.torch\"\n","Net = Net.to(device)\n","\n","for itr in range(5): # Training loop\n","    images,ann=LoadBatch() # Load taining batch\n","    images=torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n","    ann = torch.autograd.Variable(ann, requires_grad=False).to(device) # Load annotation\n","    Pred=Net(images)['out'] # make prediction\n","    Net.zero_grad()\n","\n","    Loss=criterion(Pred,ann.long()) # Calculate cross entropy loss\n","    Loss.backward() # Backpropogate loss\n","    optimizer.step() # Apply gradient descent change to weight\n","    seg = torch.argmax(Pred[0], 0).cpu().detach().numpy()  # Get  prediction classes\n","    print(itr,\") Loss=\",Loss.data.cpu().numpy())\n","\n","    if Loss.data.cpu().numpy() < Best_loss[0]:\n","        Best_loss[0] = Loss.data.cpu().numpy()\n","        np.savetxt(repo + 'Best_loss.txt',Best_loss,fmt = '%f')\n","        print(\"best loss is saved:\" + str(Best_loss[0]))\n","        torch.save(Net.state_dict(), model_path)\n","        print(\"model is saved:\")"],"metadata":{"id":"mTlfojSX4IW9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691140778669,"user_tz":-60,"elapsed":34166,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}},"outputId":"f670af64-0c9a-4754-f3a1-985420a78e72"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["0 ) Loss= 0.69061303\n","best loss is saved:0.69061303\n","model is saved:\n","1 ) Loss= 0.6734091\n","best loss is saved:0.6734091\n","model is saved:\n","2 ) Loss= 0.6780588\n","3 ) Loss= 0.65889704\n","best loss is saved:0.65889704\n","model is saved:\n","4 ) Loss= 0.673522\n"]}]},{"cell_type":"markdown","source":["Read all data for training"],"metadata":{"id":"JekNd8iLbeCf"}},{"cell_type":"code","source":["Best_loss = np.loadtxt(repo + 'Best_loss.txt').tolist()\n","Best_loss = [Best_loss]\n","Learning_Rate=1e-6\n","model_path = repo + \"weight.torch\"\n","Net.load_state_dict(torch.load(model_path))\n","Net = Net.to(device)\n","Best_loss\n","width=height=800 # image width and height"],"metadata":{"id":"3zekBtIdbdof","executionInfo":{"status":"ok","timestamp":1691158598888,"user_tz":-60,"elapsed":509,"user":{"displayName":"shipeng zheng (100T)","userId":"04144686167514371121"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["width=height=800 # image width and height\n","for itr in range(1): # Training loop\n","    start = 1\n","    end = 9000\n","    step = batchSize\n","    for i in range(start, end + 1, step):\n","        if i+2 <= end:\n","            images,ann=LoadBatchAll(i) # Load taining batch\n","            images=torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n","            ann = torch.autograd.Variable(ann, requires_grad=False).to(device) # Load annotation\n","            Pred=Net(images)['out'] # make prediction\n","            Net.zero_grad()\n","\n","            Loss=criterion(Pred,ann.long()) # Calculate cross entropy loss\n","            Loss.backward() # Backpropogate loss\n","            optimizer.step() # Apply gradient descent change to weight\n","            seg = torch.argmax(Pred[0], 0).cpu().detach().numpy()  # Get  prediction classes\n","            print(itr,\") \" + str(i) + \" Loss=\",Loss.data.cpu().numpy())\n","\n","            if Loss.data.cpu().numpy() < Best_loss[0]:\n","                Best_loss[0] = Loss.data.cpu().numpy()\n","                np.savetxt(repo + 'Best_loss.txt',Best_loss,fmt = '%f')\n","                print(\"best loss is saved:\" + str(Best_loss[0]))\n","                torch.save(Net.state_dict(), model_path)\n","                print(\"model is saved:\")"],"metadata":{"id":"KbhQwNvP4IRh"},"execution_count":null,"outputs":[]}]}